{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N7yzm1Uz2k-V"
   },
   "source": [
    "# Sujet : Independant Set\n",
    "Etant donné un corpus, l’objectif est de décrire chaque document par un ensemble de termes diversifiés ayant de fortes\n",
    "valeurs TF-IDF.\n",
    "\n",
    "Chaque document est prétraité pour détecter des termes (mots ou groupes de mots)\n",
    "On sélectionne les termes ayant une valeur supérieure à un seuil fixé (paramètre du programme). On crée un graphe de similarité G entre ces termes. On\n",
    "calcule ensuite plusieurs maximal independent sets de G comprenant le terme t ayant le score TF-IDF le plus élevé. \n",
    "\n",
    "Parmi les maximal independent sets ainsi créés, on identifie celui dont la somme des poids (les poids des sommets sont ici les valeurs TF-IDF des termes) est maximale. Un programme est ensuite créé qui permet pour un document donné\n",
    "(passé comme argument) d’afficher son graphe G avec les sommets appartenant au meilleur independent set en rouge et les autres en bleu."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nz0vO2oUf3Eb"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "Ce notebook a été codé pour répondre au sujet en permettant à l'utilisateur de choisir plusieurs paramètres au fur et à mesure de l'exécution des cellules (choix du jeu de données, de la taille, du seuil de similarité ...). Cette approche nous permet de détailler chacune des étapes et nous a semblé plus claire pour expliquer notre démarche. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "W_j7I_pA3QQc"
   },
   "source": [
    "## Importation des packages et téléchargements des bibliothèques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "meCSa1J12Vmx"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "import nltk\n",
    "from nltk import *\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer  \n",
    "\n",
    "import string\n",
    "\n",
    "from gensim import *\n",
    "from gensim.utils import simple_preprocess\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "from smart_open import smart_open\n",
    "\n",
    "import os\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "import spacy \n",
    "\n",
    "#python -m spacy download en_core_web_sm\n",
    "import en_core_web_sm\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84
    },
    "colab_type": "code",
    "id": "5e8L-XtW2VnB",
    "outputId": "527aaf16-5e70-453f-fc52-909f7078ed7b"
   },
   "outputs": [],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "nlp = en_core_web_sm.load()\n",
    "\n",
    "stop_list = stopwords.words('english') \n",
    "exclude = set(string.punctuation)\n",
    "lemmatizer = WordNetLemmatizer() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dSXh8c7sVjtc"
   },
   "source": [
    "## Sélection des paramètres"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "90Hv6fWJaiHm"
   },
   "source": [
    "### Choix du jeu de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "bhzDMG5Lal4i",
    "outputId": "ceaf6ff4-3944-42ca-f94f-670353cbd093"
   },
   "outputs": [],
   "source": [
    "while True:\n",
    "    try:\n",
    "        choixdata = int(input(\"Vous avez le choix entre 2 jeux de données : NG20 (numero 1) et Classic3 (numero 2) \\n\"))\n",
    "        if choixdata == 1 or choixdata == 2 : \n",
    "            break\n",
    "        else :\n",
    "            print(\"La valeur n'est pas entre 0 et 1\")\n",
    "            pass\n",
    "    except:\n",
    "        print(\"Ce n'est pas une entrée correcte\")\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gfNs3uGqVb5-"
   },
   "source": [
    "### Taille du jeu de données\n",
    "Attention, utiliser 100% du jeu de données peut considérablement augmenter le temps de traitement et notamment lors du calcul de la similarité"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q21eNjWCVb5_"
   },
   "outputs": [],
   "source": [
    "while True:\n",
    "    try:\n",
    "        datasize = float(input(\"Entrez le pourcentage du jeu de données que vous voulez utiliser entre 0 et 1, le nombre doit être séparé par un point : \"))\n",
    "        if 0 <= datasize <= 1 : \n",
    "            break\n",
    "        else :\n",
    "            print(\"La valeur n'est pas entre 0 et 1\")\n",
    "            pass\n",
    "    except:\n",
    "        print(\"Ce n'est pas une entrée correcte\")\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SaceVRfJ3cY5"
   },
   "source": [
    "### Similarité\n",
    "Les arrêtes du graphe correspondent à la similarité entre deux mots. Pour un souci de lisibilité et d'interêt, il est nécessaire d'utiliser une valeur de similarité minimale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 73
    },
    "colab_type": "code",
    "id": "J3GKWvoL2VnV",
    "outputId": "15bfa827-8bce-4937-cb5a-4ab4bbd7d6d6"
   },
   "outputs": [],
   "source": [
    "while True:\n",
    "    try:\n",
    "        myweights = float(input(\"Entrez la valeur du filtre de similarité entre 0 et 1, le nombre doit être séparé par un point : \"))\n",
    "        if 0 <= myweights <= 1 : \n",
    "            break\n",
    "        else :\n",
    "            print(\"La valeur n'est pas entre 0 et 1\")\n",
    "            pass\n",
    "    except:\n",
    "        print(\"Ce n'est pas une entrée correcte\")\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "d-tmrlB7VqLI"
   },
   "source": [
    "### Valeur du TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0yLN_UMOVb6I"
   },
   "outputs": [],
   "source": [
    "while True:\n",
    "    try:\n",
    "        filTFIDF = float(input(\"Entrez la valeur du filtre du TFIDF entre 0 et 1, le nombre doit être separé par un point : \"))\n",
    "        if 0 <= filTFIDF <= 1 : \n",
    "            break\n",
    "        else :\n",
    "            print(\"La valeur n'est pas entre 0 et 1\")\n",
    "            pass\n",
    "    except:\n",
    "        print(\"Ce n'est pas une entrée correcte\")\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rBN4kWOT3X00"
   },
   "source": [
    "## Chargement de la base de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0WG93Q4A2VnN"
   },
   "outputs": [],
   "source": [
    "if choixdata == 1 : \n",
    "  with open(\"classic3_raw.txt\") as file:\n",
    "    content = file.read()\n",
    "  content = content.split(\"\\n\")\n",
    "else : \n",
    "  ng = fetch_20newsgroups(remove=('headers', 'footers', 'quotes'))  \n",
    "  content = ng.data\n",
    "\n",
    "content = random.sample(content, int(round(len(content) * datasize)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nHcUorLV32R_"
   },
   "source": [
    "## Text cleaning\n",
    "\n",
    "Pour le moment le texte est brute. Avant de pouvoir l'analyser, une première étape de nettoyage est nécessaire.   \n",
    "Nous retirons donc : \n",
    "*   Les nombres\n",
    "*   Les majuscules\n",
    "*   Les mots de liaison\n",
    "*   La ponctuation et les caractères spéciaux\n",
    "\n",
    "La lemmatisation de chacun des mots du corpus est ensuite effectuée afin de regrouper tous les mots de même famille sous une seule et même forme, la forme canonique.   \n",
    "Exemple : sleeps devient sleep\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5glrPZcr2Vnd"
   },
   "outputs": [],
   "source": [
    "reviews_corpus = []\n",
    "for a in content:\n",
    "    if len(a) > 1:\n",
    "        a = ''.join([i for i in a if not i.isdigit()])\n",
    "        a = ''.join(ch for ch in a if ch not in exclude)\n",
    "        a = a.lower()\n",
    "        a = ' '.join([word for word in a.split() if word not in stop_list])\n",
    "        a = ' '.join([lemmatizer.lemmatize(word) for word in a.split() ])\n",
    "        reviews_corpus.append(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "G12_WGO85AiE"
   },
   "source": [
    "Le dictionnaire des mots uniques du corpus est ensuite créé."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ciP8nn4H2Vnl"
   },
   "outputs": [],
   "source": [
    "texts = [[text for text in doc.split()] for doc in reviews_corpus]\n",
    "dictionary = corpora.Dictionary(texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2rOibHrr5M_E"
   },
   "source": [
    "Nous comptons, ensuite, la fréquence des mots dans le corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "74hTM54e2Vny"
   },
   "outputs": [],
   "source": [
    "tokenized_list = [simple_preprocess(doc) for doc in reviews_corpus]\n",
    "\n",
    "mydict = corpora.Dictionary()\n",
    "mycorpus = [mydict.doc2bow(doc, allow_update=True) for doc in tokenized_list]\n",
    "word_counts = [[(mydict[id], count) for id, count in line] for line in mycorpus]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1vKcB6ZGdAIw"
   },
   "source": [
    "## Utilisation des mots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tQCLZPYj5VnM"
   },
   "source": [
    "### TF IDF\n",
    "Afin de créer le graphe, il faut calculer la valeur TF-IDF de chaque mot du corpus.\n",
    "\n",
    "**Définition** : Cette mesure statistique permet d'évaluer l'importance d'un terme contenu dans un document, relativement à une collection ou un corpus. Le poids augmente proportionnellement au nombre d'occurrences du mot dans le document. Il varie également en fonction de la fréquence du mot dans le corpus. Des variantes de la formule originale sont souvent utilisées dans des moteurs de recherche pour apprécier la pertinence d'un document en fonction des critères de recherche de l'utilisateur.\n",
    "\n",
    "Pour calculer le TF IDF, nous avons découpé le document en phrase. Le calcul est donc la récurrence d'un mot dans la phrase ainsi que dans le reste des phrases du document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y5WI-lqi2Vn_"
   },
   "outputs": [],
   "source": [
    "tfidf = models.TfidfModel(mycorpus, smartirs='ntc')\n",
    "tt_tfidf = []\n",
    "# Show the TF-IDF weights\n",
    "for doc in tfidf[mycorpus]:\n",
    "    val = [[mydict[id], np.around(freq, decimals=2)] for id, freq in doc]\n",
    "    tt_tfidf.append(val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Gnyl_0vY57oJ"
   },
   "source": [
    "### Bigramme\n",
    "\n",
    "Il existe plusieurs manière de créer un graphe. Dans notre cas, nous avons decidé de créer l'ensemble des combinaisons de deux mots présents dans le corpus. Pour cela, nous allons créer des bi-grammes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MxYo2_F-2VoV"
   },
   "outputs": [],
   "source": [
    "mylist = []\n",
    "for gram in tt_tfidf : \n",
    "    for i in gram : \n",
    "        mylist.append(i)\n",
    "mylist = [t for t in mylist if t[1]> filTFIDF]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZhRvAVXyVb6d"
   },
   "outputs": [],
   "source": [
    "voc = []\n",
    "for i in mylist : \n",
    "    voc.append(i[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iHmwsSVhVb6f"
   },
   "outputs": [],
   "source": [
    "verif = []\n",
    "test = []\n",
    "for i in range(len(texts)) : \n",
    "    test.append(list(set([num for num in texts[i] if num in voc])))\n",
    "test= [x for x in test if x != []]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HTpv7pQ32VoL"
   },
   "outputs": [],
   "source": [
    "bigramme = []\n",
    "for gramm in test : \n",
    "    bigram=list(ngrams(gramm,2))\n",
    "    bigramme.append(bigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yYYoau6_Vb6j",
    "outputId": "32da1e09-2e6f-4a43-c190-78b3a825ce13"
   },
   "outputs": [],
   "source": [
    "fin = []\n",
    "for gram in bigramme : \n",
    "    for i in gram : \n",
    "        fin.append(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qNulxoB26Srx"
   },
   "source": [
    "### Indicateur de similarité\n",
    "Les liens entre les mots représentent leur similarité. La force des lien dépend donc des valeurs de similarité.\n",
    "\n",
    "A nouveau, il existe un certain nombres de méthodes allant du nombre de lettres en commun à la proportion de lettres ordonnées de la même manière. \n",
    "Nous avons utilisé la méthode de similarité implémentée dans le package Spacy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bLZ4c7eD2Vok",
    "outputId": "758fbebb-b681-4f78-dc67-aecbdf90cfe5"
   },
   "outputs": [],
   "source": [
    "top = list()\n",
    "for i in fin:\n",
    "    token1 = nlp(i[0])\n",
    "    token2 = nlp(i[1])\n",
    "    sim = token1.similarity(token2)\n",
    "    vol = (str(token1), str(token2), sim)\n",
    "    top.append(vol)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HxbZzT1k8XD2"
   },
   "source": [
    "Pour améliorer la lisibilité du graphe, nous mutiplions la similarité par 10, et la passons à l'exponentiel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F8ZONR7L2Vos"
   },
   "outputs": [],
   "source": [
    "tt = [math.exp(x[1]*11) for x in mylist]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YoTCWCGH8lHy"
   },
   "source": [
    "## Création du graphe\n",
    "\n",
    "Tout d'abord, nous regroupons les informations utiles dans une nouvelle table. Celle-ci contient une colonne pour le premier mot, une colonne pour le second et une dernière pour le poids (valeur de similarité) qui leur correspond.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RfoFte-J2Vo3"
   },
   "outputs": [],
   "source": [
    "test = pd.DataFrame(top, columns = [\"from\", \"to\", \"weights\"])\n",
    "tuples = [tuple(x) for x in test.to_numpy()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s6dsqTDi9GUI"
   },
   "source": [
    "### Initialisation du graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hLKNQ0Qw2Vo-"
   },
   "outputs": [],
   "source": [
    "g = nx.Graph()\n",
    "g.add_weighted_edges_from(tuples)\n",
    "edges,weights = zip(*nx.get_edge_attributes(g,'weight').items())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TbV5djTo9O1s"
   },
   "source": [
    "### Calcul du maximum independante set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VgLcCBT32VpT"
   },
   "outputs": [],
   "source": [
    "maxindep = pd.DataFrame(nx.maximal_independent_set(g))\n",
    "maxindep = maxindep[0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "te8QEJHF2Vpg"
   },
   "outputs": [],
   "source": [
    "df_tfidf = pd.DataFrame(mylist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rT2PZ4PR_ZYN"
   },
   "source": [
    "Mise en place des couleurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ojO7iZyw_bVo"
   },
   "outputs": [],
   "source": [
    "color_map = []\n",
    "for node in g:\n",
    "    if node in maxindep:\n",
    "        color_map.append('red')\n",
    "    else: \n",
    "        color_map.append('blue') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8HYOCGj_9LVq"
   },
   "source": [
    "### Dessin du graphe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iT8X742U2VpE"
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (30,30))\n",
    "ax = plt.subplot(111)\n",
    "ax.set_title('Graph')\n",
    "pos = nx.spring_layout(g)\n",
    "nx.draw(g, pos, node_color=color_map, \n",
    "        edgelist=edges, edge_color=weights, \n",
    "        width=10.0, edge_cmap=plt.cm.Blues, \n",
    "        node_size = tt, with_labels=True)\n",
    "plt.savefig(\"graph.png\", format=\"PNG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iTGapGM02Vpm",
    "outputId": "a8780288-79ef-4b72-8d29-9db4694d12f3"
   },
   "outputs": [],
   "source": [
    "mergeindep = pd.merge(maxindep, df_tfidf, on = 0)\n",
    "mergeindep[1].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EhhJ9xchgxJk"
   },
   "source": [
    "# Conclusion \n",
    "Ce projet nous a permi d'aborder plusieurs problématiques de text mining (nettoyage de données, volumétrie ...). \n",
    "Nous avons été confronté, par exemple, au choix entre l'utilisation de l'ensemble du jeu de données (exhaustivité et meilleure représentativité du graphe obtenu) et le temps d'exécution. Pour que l'utilisateur puisse faire ce choix lui-même nous avons proposé à plusieurs reprises de filter le jeu de données (par exemple sur les valeurs de la similarité ou celle des TF IDF). \n",
    "\n",
    "Pour poursuivre, il serait intéressant de calculer la similarité avec d'autres méthodes afin de comparer les performances obtenues (temps de traitement, graphe résultats)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RCs8TSwLkiwC"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Clean_TM_save.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
